{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping the first page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.bamako-immobilier.com/Location_Appartements.html\"\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "# Main pages: get the main pages that contains the list of ads/annonces.\n",
    "# when novigating we click on \"next page\". This code grab all the pages.\n",
    "t = soup.find(id = \"searchbar\", class_= \"row\")\n",
    "hrefs = t.find_all(href = True)\n",
    "m_pages = [x.get(\"href\") for x in hrefs]\n",
    "for i in range(len(m_pages)):\n",
    "    m_pages[i] = \"https://www.bamako-immobilier.com/\" + m_pages[i]\n",
    "\n",
    "m_first_page = \"https://www.bamako-immobilier.com/index.php?cur_page=0&&sortby=Prix&sorttype=ASC&type=Location&bien=Appartements&action=searchresults\"\n",
    "m_pages.append(m_first_page)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping - page containing list of Ads/annonces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  from the main pages: get each annonce page title & link\n",
    "def annonces_titles_links(main_pages):\n",
    "    # main_pages : is a list type\n",
    "    \n",
    "    all_titles = []\n",
    "    all_links = []\n",
    "    \n",
    "    for i in range(len(main_pages)):\n",
    "        url = main_pages[i]\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "        # annonces titles\n",
    "        annonce = soup.find_all(class_= \"line mt1\")\n",
    "        a_titles = [a.get_text() for a in annonce]\n",
    "        if len(a_titles) > 0:\n",
    "            for x in a_titles:\n",
    "                all_titles.append(x)\n",
    "    \n",
    "        # annonces links\n",
    "        href_tags = soup.find_all(class_=\"icon-rate\")\n",
    "        a_links = [x.get(\"href\") for x in href_tags]\n",
    "        if len(a_links) > 0:\n",
    "            for i in range(len(a_links)):\n",
    "                a_links[i] = \"https://www.bamako-immobilier.com//\" + a_links[i]\n",
    "                all_links.append(a_links[i])\n",
    "\n",
    "    data = {\"title\": all_titles, \"link\": all_links}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping - Main page of Ad/annonce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from annonce page: get details (sub_title, description, prix, nombre de chambres, nombre de pieces)\n",
    "def annonce_details(annonce_links):\n",
    "    # annonce_links: is a list type\n",
    "    \n",
    "    all_sub_titles = []\n",
    "    all_desc = []\n",
    "    all_villes = []\n",
    "    all_prix = []\n",
    "    all_num_chambres = []\n",
    "    all_num_pieces = []\n",
    "    all_loyer_mensuel = []\n",
    "    \n",
    "    for i in range(len(annonce_links)):\n",
    "        url = annonce_links[i]\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        init = soup.find(class_= \"zonegris mt2\")\n",
    "\n",
    "        # grab annonce sub_title\n",
    "        t = init.h2\n",
    "        sub = [x.get_text() for x in t][1]\n",
    "        all_sub_titles.append(sub)\n",
    "        \n",
    "        # annonce description\n",
    "        annonce = init.find(class_= \"row mt1\")\n",
    "        desc = [x.get_text(strip= True) for x in annonce]\n",
    "        for x in desc:\n",
    "            if len(x) > 0:\n",
    "                x = x.replace(\"Descriptif: \", \"\")\n",
    "                all_desc.append(x)\n",
    "    \n",
    "        # grab more infos about annonce\n",
    "        temp_list = []\n",
    "        m_info = init.find(class_= \"row grid2\")\n",
    "        for x in m_info:\n",
    "            t = x.get_text(strip=True, separator='\\n').splitlines()\n",
    "            if len(t) > 0:\n",
    "                temp_list = temp_list + t\n",
    "        \n",
    "        # Get ville\n",
    "        if 'Ville' not in temp_list:\n",
    "            all_villes.append(np.nan)\n",
    "        else:\n",
    "            for i in range(len(temp_list)):\n",
    "                if temp_list[i] == 'Ville':\n",
    "                    all_villes.append(temp_list[i+1].replace(\": \", \"\"))  \n",
    "\n",
    "        # Get Nombre de chambres\n",
    "        if 'Nombre de chambres' not in temp_list:\n",
    "            all_num_chambres.append(np.nan)\n",
    "        else:\n",
    "            for i in range(len(temp_list)):\n",
    "                if temp_list[i] == 'Nombre de chambres':\n",
    "                    all_num_chambres.append(temp_list[i+1].replace(\":\", \"\"))  \n",
    "\n",
    "        # Get Nombre de pieces\n",
    "        if 'Nombre de pièces' not in temp_list:\n",
    "            all_num_pieces.append(np.nan)\n",
    "        else:\n",
    "            for i in range(len(temp_list)):\n",
    "                if temp_list[i] == 'Nombre de pièces':\n",
    "                    all_num_pieces.append(temp_list[i+1].replace(\":\", \"\"))  \n",
    "\n",
    "        # Get loyer mensuel\n",
    "        if 'Loyer mensuel' not in temp_list:\n",
    "            all_loyer_mensuel.append(np.nan)\n",
    "        else:\n",
    "            for i in range(len(temp_list)):\n",
    "                if temp_list[i] == 'Loyer mensuel':\n",
    "                    all_loyer_mensuel.append(temp_list[i+1].replace(\":\", \"\"))  \n",
    "\n",
    "        # Get prix\n",
    "        if 'Prix' not in temp_list:\n",
    "            all_prix.append(np.nan)\n",
    "        else:\n",
    "            for i in range(len(temp_list)):\n",
    "                if temp_list[i] == 'Prix':\n",
    "                    if temp_list[i+1] == \" \" or temp_list[i+1] == \"\":\n",
    "                        all_prix.append(np.nan)\n",
    "                    else:\n",
    "                        all_prix.append(temp_list[i+1].replace(\":\", \"\"))\n",
    "\n",
    "    # recap\n",
    "    data = {\n",
    "        \"sub_title\" : all_sub_titles,\n",
    "        \"description\": all_desc,\n",
    "        \"ville\": all_villes,\n",
    "        \"prix\": all_prix,\n",
    "        \"num_chambres\": all_num_chambres,\n",
    "        \"num_pieces\": all_num_pieces,\n",
    "        \"loyer_mensuel\": all_loyer_mensuel,\n",
    "        \"link\": annonce_links\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the data & save it as a csv file\n",
    "def scrape_all(main_pages):\n",
    "    main_links = annonces_titles_links(main_pages)[\"link\"]\n",
    "    df = annonce_details(main_links)\n",
    "    df.to_csv(\"scrapping_bko_immo.csv\")\n",
    "\n",
    "scrape_all(m_pages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
